# DESCRIPTION -------------------------------------------------------------------------------------------------
# Author: Daisy Sproviero
# Date: 13th June 2023

#Purpose: quality control


## load libraries  ----------------------------------------------------------------------------------------------
library(DESeq2) #expression normalization
library(tidyverse) #for table manipulation
library(tximport) #for tximport
library(ggplot2)
library(ggrepel)
library(dplyr)
library(data.table)
library(stringr)

# Load the annotation table for GrCh38.
# tx2gene is a three-column dataframe linking transcript ID (column 1) to gene ID (column 2) to gene symbol (column 3).

getwd()
tx2gene <- read.delim("tx2gene_grch38_ens94.txt")

## List all directories containing data  

getwd()
setwd("/Users/dsprovie/Desktop/BL_salmonfiles/")
samples <- list.files(path = "./", full.names = T, pattern="salmon.transcripts.sf$")
samples


## Since all quant files have the same name it is useful to have names for each element
names(samples) <- str_replace(samples,".//","") %>% 
  str_replace(".longRNA-NEBKAP.salmon.transcripts.sf", "")

names(samples)

#### 2. Read-in data ####

# Now we are ready to run tximport. Note that although there is a column in our quant.sf files that corresponds to the estimated count value for each transcript, those valuse are correlated by effective length. What we want to do is use the countsFromAbundance=“lengthScaledTPM” argument. This will use the TPM column, and compute quantities that are on the same scale as original counts, except no longer correlated with transcript length across samples.

txi <- tximport(samples, 
                type="salmon", 
                tx2gene=tx2gene[,c("tx_id", "ensgene")], 
                countsFromAbundance="lengthScaledTPM",ignoreTxVersion = TRUE)


# Write the counts to an object(a matrix) 
data<-round(txi$counts)

# force data in the form of a data frame (i.e. transform the matrix in a dataframe)
data <- as.data.frame(data)
head(data)

## load metadata to match Salmon files

metasummary_GITHUB <- read_excel("~/Desktop/revision/metasummary_GITHUB.xlsx")
meta2 = data.frame(row.names = colnames(txi$counts),sampletype)
View(meta2)

#### 3. Normalization with DESeq2 ####
# Create DESeq2Dataset object

dds <- DESeqDataSetFromTximport(txi, 
                                colData = meta2, 
                                design = ~ sampletype)

#Pre-filtering
keep <- rowSums(counts(dds)) >= 10
dds <- dds[keep,]


####Note on factor levels
dds$condition <- factor(dds$sampletype, levels = c("PDLRKK2_rs76904798","PDLRKK2_G2019S","PDGBA","PD","Control"))

#### 4. QC at the sample level ####


View(dds)
rld <- vst(dds, blind=TRUE)
class(rld)
rld_mat <- assay(rld)
pca <- prcomp(t(rld_mat))

# Create data frame with metadata and other PCs values for input to ggplot
df <- cbind(meta2, pca$x)
ggplot(df) + 
  geom_point(aes(x=PC1, y=PC2, color = sampletype))

